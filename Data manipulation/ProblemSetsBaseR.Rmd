---
output:
  github_document:
    toc: true
    toc_depth: 1
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

knitr::opts_knit$set(root.dir = "~/RProjects/RforIEPworkshop/Data manipulation")

```

# Load Data

Read the `.csv` file into your current R session. *Note*: your file path to `file` may differ.

```{r load-data}

CBdata <- read.csv(
  file = "CBdata.csv",
  header = TRUE,
  stringsAsFactors = FALSE
)

```

# Check Data

Check your data with calls to built-in R functions. `dim` returns number of rows and number of columns. We have many columns (n=`r ncol(CBdata)`).

```{r check-data}

# check row and column count
dim(CBdata)

# long output, but a good option
# str(CBdata)
# summary(CBdata)

```

#### Check `NA`

Here, we write a custom function `CountNA` to help us count `NA`s and character NAs. We pass the function to `FUN` in `vapply` - see next step.

*Note*: for now `sum(x %in% c("NA", "na"))` will suffice to check for character NAs. Likely, there are more robust ways, perhaps even using `base::grepl` or the like.

```{r count-na-function}

CountNA <- function(x) {
  char_na <- sum(x %in% c("NA", "na"))
  c(CharNA = char_na, `NA` = sum(is.na(x)))
}

```

The output is long, but we see seven fields have count `NA` > 0. Good to know.

```{r check-na}

t(vapply(CBdata, FUN = CountNA, FUN.VALUE = numeric(2L)))

```

You'll want to develop other data-checking and (or) data-cleaning procedures as needed. For now , we'll suffice at checking `NA`s.

# Questions (from `applyfunctions.Rmd`)

#### What is the average CPUE of each species?

The first step to answering this question is which field or fields contain CPUE (catch-per-unit-effort)?

A call to `base::colnames` reveals each species is a field. Are data are in "wide" format. We also see species field names are all CAPS. This can play to our advantage, as R is case sensitive.

*Note*: we assume data in each species field are CPUE.

```{r column-names}

colnames(CBdata)

```

A call to `base::grepl` using `pattern = "[A-Z]$"` (i.e., checking for capital letters from the text end) yields `TRUE` for all species field names.

```{r species-columns}

# `b` for Boolean
b <- grepl(pattern = "[A-Z]$", x = colnames(CBdata))

sum(b)

# just for easier observartion (run as desired)
# cbind(colnames(CBdata), b)
# or...
# View(cbind(colnames(CBdata), b), title = "SpeciesFieldCheck")

```

Verify for yourself there are in fact `r sum(b)` species. Now to answer our question...simply call `base::colMeans` on the subsetted `CBdata`. Play with display format as desired (e.g., call `as.data.frame` on the `colMeans` output).

```{r mean-cpue}

colMeans(CBdata[b])

```

#### What is the maximum CPUE of Eurytemora in Suisun Bay by year?

Here we get a bit specific. We seek annual maximum CPUE for only Eurytemora in Suisun Bay. Our "filter" is Suisun Bay, and our "split" is by year. *Note*: for this purpose, we assume `EURYTEM` is the desired field.

```{r eurytem-year-split}

eurytem_year <- split(CBdata[c("Region", "EURYTEM")], f = CBdata["Year"])

```

Because, variable `eurytem_year` is a list, we can use `vapply` to loop through each year. Each element in `eurytem_year` is a data.frame with two fields: `Region` & `EURYTEM`. Our anonymous function has one parameter: `d` (short for data).

- `b <- d[["Region"]] %in% "SuiBay"` is our "filter" selecting only `SuiBay` (we assume Suisun Bay)
- `max(d[b, "EURYTEM"])` returns the maximum value --- a single numeric --- on the subsetted data (just to be safe you could include `, na.rm = TRUE` but we know from our clean data check no `NA`s exist in our species fields)

Output below can be assigned to a variable, and then plotted if desired.

```{r eurytem-year-max}

vapply(eurytem_year, FUN = function(d) {
  b <- d[["Region"]] %in% "SuiBay"
  max(d[b, "EURYTEM"])
}, FUN.VALUE = numeric(1L))

```

#### Calculate the relative % composition of each species by year (this is a hard one).

We assume we are to use CPUE values (i.e., in our wide format, each species column).

**Step 1**: `split` all species data by year. Recall our variable `b`, which gave `TRUE` for field names with all caps (i.e., species names).

```{r species-year}

species_year <- split(CBdata[b], f = CBdata[["Year"]])

```

Now each element in list `species_year` represents a year. Run `str(species_year[["2018"]])` as an example to verify this element is a dataframe with `r sum(b)` variables. Try other years, too, if you wish.

**Step 2**: Each row in the data.frame (either `CBdata` or `species_year`) represents a sampling event (i.e, date-station-tow). If we sum each species (i.e., each column), we get the yearly total. So here we need a call to `base::colSums`. Below works, but we need "relative % composition".

```{r col-sums-demo}

species_year_total <- t(
  vapply(species_year, FUN = colSums, FUN.VALUE = numeric(sum(b)))
)

```

**Step 3**: A call to `base::prop.table` should do the trick. `margin = 1` indicates by rows (i.e., by year). *Note*: If not using a call to `t` like above, then set `margin = 2` for columns.

```{r rel-percent-comp}

rel_percent_comp <- prop.table(species_year_total, margin = 1)

# double-check rows should sum to 1
# rowSums(rel_percent_comp)

# for ease of viewing rather than in the console
# View(rel_percent_comp)

```

# Questions (from `data mainpulaton.Rmd`)

Here, we will continue to use data.frame `CBdata`.


#### How many samples does the Zooplankton survey have from the North Delta that contain Harpacticoids (HARPACT)?

A call to `base::table` on field `Region` returns 700+ records North Delta (we assume `NorDel` = North Delta). Further, we display CPUE range for our desired zooplankton (`HARPACT`).

```{r table-region}

table(CBdata[["Region"]], useNA = "ifany")

range(CBdata[["HARPACT"]])

```

We can answer the question using Boolean values. <code>CBdata[["HARPACT"]] > 0</code> returns `TRUE` for all samples with `HARPACT`, and `CBdata[["Region"]] %in% "NorDel"` returns `TRUE` for all North Delta samples. We want the count of records (samples) when both are `TRUE`. Because `TRUE` = 1 and `FALSE` = 0, summing the result should give us the number we desire. *Note*: we assume each row in `CBdata` is a sample.

```{r north-detla-samples}

sum(CBdata[["HARPACT"]] > 0 & CBdata[["Region"]] %in% "NorDel")

```

Our result should be less than the `NorDel` value in the `table` result above.

#### Make a new variable for the total catch of all zooplankton.

Recall our variable `b`, which selects all zooplankton (species) fields in `CBdata`.

```{r total-catch}

total_species_catch <- sum(CBdata[b])

# display
total_species_catch

# or with formatting possibilities
format(total_species_catch, big.mark = ",")
format(total_species_catch, digits = 3, scientific = TRUE)

```

#### Create a new data frame that only contains samples with positive occurrences of Eurytemora (EURYTEM).

We need a filter (only positive occurrences) and field selection (all non-species fields + `EURYTEM`). If variable `b` selects for all zooplankton fields, then `!b` is everything else.

```{r fields}

# create our desired fields
# we assume the only zooplankton field we want is EURYTEM
fields <- c(colnames(CBdata)[!b], "EURYTEM")

fields

```

```{r eurytem_catch}

# our filter: CBdata[["EURYTEM"]] > 0

eurytem_catch <- CBdata[CBdata[["EURYTEM"]] > 0, fields]

dim(eurytem_catch)
colnames(eurytem_catch)
range(eurytem_catch[["EURYTEM"]])

```

# Questions (from `dataset restructuring.Rmd`)

#### Import the "Station_GPS.csv" into your environment and merge the latitude and longitude to the "CBlong" data frame.

So let us first create a long format of `CBdata`. We can use `stats::reshape`. For help, run `?reshape` in your R console, see example using `state.x77`.

For simplicity, we will arbitrarily use `ACARTELA` & `EURYTEM`, rather than all `r sum(b)` species.

```{r cb-long}

# for simplicity
species <- c("ACARTELA", "EURYTEM")

# to remove fields we don't want in the long format
drop_species <- Filter(
  f = function(nms) !(nms %in% species),
  x = colnames(CBdata)[b]
)

# create the long format from wide CBdata
cb_long <- reshape(
  data = CBdata,
  varying = species,
  # varying = list(species),
  v.names = "CPUE",
  timevar = "Species",
  # idvar = "RowId",
  # ids = "",
  times = species,
  drop = drop_species,
  direction = "long",
  new.row.names = seq_len(nrow(CBdata) * length(species))
)

```

Let's run some 'checks' to verify `reshape` worked as we anticipated. The newly-created `cb_long` should have twice as many rows as `CBdata`, or `r 2 * nrow(CBdata)`. We included all non-species fields (n=`r sum(!b)`) and created three new fields: `CPUE`; `Species`; and (default) `id`. So we should now have `r sum(!b) + 3` fields.

```{r check1-long}

dim(cb_long)

```

Check field `Species` with a call to `base::table`. Frequency should equal value returned by `nrow(CBdata)`.

```{r check2-long}

table(cb_long[["Species"]]) == nrow(CBdata)

```

Because field `id` is the row number of `CBdata`, calling `table(cb_long[["id"]])` should yield all `r length(species)`s or `length(species)`.

```{r check3-long}

all(table(cb_long[["id"]]) == length(species))

```

...and finally, mean CPUE should be the same between formats wide and long. If not, we need to recheck our work. *Note*: mean is just one example. You can use other checks as you see fit or wherever your creativity takes you.

```{r check4-long}

# wide means
colMeans(CBdata[species])

# long means
species_split <- split(cb_long[["CPUE"]], f = cb_long["Species"])
vapply(species_split, FUN = mean, FUN.VALUE = numeric(1L))

```

Now, we will load our lat-lon data.

```{r load-data}

StationsGPS <- read.csv(
  file = "Stations_GPS.csv",
  header = TRUE,
  stringsAsFactors = FALSE
)

```

Let us check field data types.

```{r str-station-gps}

str(StationsGPS)

```

`Latitude` and `Longitude` are type character. Ideally these data should be numeric. We can check for non-numerics using `base::grep`

```{r check-letters}

grep(pattern = "[A-Za-z]", x = StationsGPS[["Latitude"]], value = TRUE)
grep(pattern = "[A-Za-z]", x = StationsGPS[["Longitude"]], value = TRUE)

```

It appears we have `#VALUE!` as a value instead of NA. Let us change that, and then convert lat-lon to numeric.

```{r numeric-coords}

# if statements return data as-is; we don't want to change these data
StationsGPS[] <- lapply(StationsGPS, FUN = function(x) {
  if (is.numeric(x)) return(x)
  b <- grepl(pattern = "[A-Za-z]", x = x)
  if (all(b)) return(x)
  x[x %in% "#VALUE!"] <- NA
  as.numeric(x)
})

# recheck
str(StationsGPS)

```

Beautiful!

Now we could use `base::merge`, but here we'll create variable `index` using `base::match`. We `match` on the common field `Station`. Wherever the values match, `index` contains the row number from `StationsGPS`, NA otherwise.

```{r index}

index <- match(cb_long[["Station"]], table = StationsGPS[["Station"]])

# check length - should be TRUE
length(index) == nrow(cb_long)

# check NAs (ideally 0)
sum(is.na(index))

# check range
range(index)

```

`length(unique(index))` = `r length(unique(index))`, one less than `nrow(StationsGPS)` or `r nrow(StationsGPS)`. Station `NZM12` is not really a monitoring station. To save time, run `View(StationsGPS[86, ])` to verify. (If you recall, record 86 had lat-lon as `#VALUE!`.)

Now, use `index` to add lat-lon fields to `cb_long`.

```{r add-coord-fields}

cb_long$Latitude <- StationsGPS[index, "Latitude"]
cb_long$Longitude <- StationsGPS[index, "Longitude"]

# confirm
colnames(cb_long)
range(cb_long[["Latitude"]], na.rm = TRUE)
range(cb_long[["Longitude"]], na.rm = TRUE)

```

#### Convert your new data frame (with lats and longs) back to "wide" format.

```{r}

# create the long format from wide CBdata
cb_wide <- reshape(data = cb_long, direction = "wide")

# check
colMeans(CBdata[species])
colMeans(cb_wide[species])

# coord range check
range(cb_wide[["Latitude"]], na.rm = TRUE)
range(cb_long[["Latitude"]], na.rm = TRUE)

range(cb_wide[["Longitude"]], na.rm = TRUE)
range(cb_long[["Longitude"]], na.rm = TRUE)

# should be TRUE
length(unique(cb_wide[["id"]])) == nrow(CBdata)

```

#### Save you new data frame as a .csv.

not run

```{r save-wide, eval=FALSE}

write.csv(cb_wide, file = "CBDataWide.csv", row.names = FALSE)

```

---
run: `r format(Sys.time(), format = "%B %d %Y @ %H%M")`  
&copy; IEP educational series
